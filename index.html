<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Shreyas Verma</title>

    <meta name="author" content="Shreyas Verma">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Shreyas Verma
                </p>
                <p>Hi there! I am Gen AI Research Scientist at <a href="https://www.asurion.com/">Asurion</a> based out of San Francisco,CA . I work with a small team of passionate AI Engineers working towards redefining customer tech troubleshooting industry using Agentic AI.  
                </p>
                <p>
                 At Asurion, I have worked extensively on building production-grade Conversational AI Agents. I have led research efforts on solving the "latency problem" of an AI chatbot with efficient memory management,robust semantic caching, parallelization of guardrail prompts and optimizing RAG pipelines. 
                </p>
                <p>
                  I also interned as an Applied Scientist with the Search & Discovery AI team at <a href="https://www.zillow.com/">Zillow</a>, where I worked on building Multimodal Representations for homes using contrastive learning techniques - considerably improving upon the <a href="https://www.zillow.com/homedetails/2758-Montecito-Vista-Way-UNIT-3-San-Jose-CA-95111/300480585_zpid/">Similar Homes</a> downstream recommendation task.
                 </p>
                 <p>
                  I am completed my Master's degree in Computational Data Science from <a href="https://www.gatech.edu/">Georgia Tech</a> in 2023 and my Bachelors in Engineering degree from <a href="http://www.bits-pilani.ac.in/">BITS Pilani</a>.
                 </p>
                <p style="text-align:center">
                  <a href="mailto:shreyas301197@gmail.com">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <a href="data/Shreyas_Verma_Resume_AS.pdf">Resume</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=j6dIihMAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/shreyas-verma/">LinkedIn</a> 
                  <!-- <a href="https://bsky.app/profile/jonbarron.bsky.social">Bluesky</a> &nbsp;/&nbsp; -->
                  <!-- <a href="https://github.com/jonbarron/">Github</a> -->
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/ShreyasVerma.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/ShreyasVerma.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am passionate about working towards building efficient Small Language Models (SLMs). I have hands-on experience with creating mid-training as well as post-training LLM Alignment pipelines for tech support domain. I have worked extensively towards <a href="https://arxiv.org/abs/2410.14702">building</a> as well as <a href="https://arxiv.org/pdf/2501.14249">contributing</a> to state-of-the-art LLM benchmarks for evaluations as well as <a href="https://arxiv.org/abs/2310.17876">creating synthetic datasets</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='polymath_teaser'><video  width=100% height=100% muted autoplay loop>
          <source src="images/polymath_teaser.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/polymath_teaser.png' width="160">
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://polymathbenchmark.github.io/">
			<span class="papertitle">Polymath: A Challenging Multi-modal Mathematical Reasoning Benchmark
</span>
        </a>
        <br>
				<a href="https://him1411.github.io/">Himanshu Gupta</a>,
				<strong>Shreyas Verma</strong>,
				<a href="https://ujjwalaananth.github.io/">Ujjwala Anantheswaran</a>,
				<a href="https://kevinscaria.github.io/">Kevin Scaria</a>,
        <a href="https://sites.google.com/view/mihir3009">Mihir Parmar</a>,
        <a href="https://swarooprm.github.io/">Swaroop Mishra</a>,
        <a href="https://search.asu.edu/profile/231973">Chitta Baral</a>
        <br>
        <a href="https://arxiv.org/abs/2410.14702">arXiv</a> /
        <a href="https://polymathbenchmark.github.io/">website</a>
        /
        <a href="https://github.com/polymathbenchmark/PolyMATH">code</a> /
        <a href="https://huggingface.co/datasets/him1411/polymath">dataset</a>
        <p>
          A challenging benchmark aimed at evaluating the general cognitive reasoning abilities of Multi-modal Large Language Models (MLLMs), PolyMATH comprises 5,000 manually collected high-quality images of cognitive textual and visual challenges across 10 distinct categories, including pattern recognition, spatial reasoning, and relative reasoning. 
        </p>
      </td>
    </tr>

    <tr >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='targen_teaser.png'><video  width=100% height=100% muted autoplay loop>
          <source src="images/targen_teaser.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/targen_teaser.png' width="160">
        </div>
      </td>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2310.17876">
			<span class="papertitle">TarGEN: Targeted Data Generation with Large Language Models
</span>
        </a>
        <br>
				<a href="https://him1411.github.io/">Himanshu Gupta</a>,
				<a href="https://ujjwalaananth.github.io/">Ujjwala Anantheswaran</a>,
				<a href="https://kevinscaria.github.io/">Kevin Scaria</a>,
        <strong>Shreyas Verma</strong>,
        <a href="https://sites.google.com/view/mihir3009">Mihir Parmar</a>,
        <a href="https://swarooprm.github.io/">Swaroop Mishra</a>,
        <a href="https://search.asu.edu/profile/231973">Chitta Baral</a>  
        <br>
        <font color=#FF8080><em>CoLM</em>, 2024</font> &nbsp;
        <br>
        <a href="https://arxiv.org/abs/2310.17876">arXiv</a> 
        <!-- <a href="https://polymathbenchmark.github.io/">website</a> -->
        <!-- <a href="https://github.com/polymathbenchmark/PolyMATH">code</a> / -->
        <!-- <a href="https://huggingface.co/datasets/him1411/polymath">dataset</a> -->
        <p>
          In this paper, we present TarGEN, a multi-step prompting strategy for generating high-quality synthetic datasets utilizing a LLM. An advantage of TarGEN is its seedless nature; it does not require specific task instances, broadening its applicability beyond task replication. 
        </p>
      </td>
    </tr>


    <tr >
      <td style="padding:16px;width:20%;vertical-align:top">
        <div class="one">
          <div class="two" id='targen_teaser.png'><video  width=100% height=100% muted autoplay loop>
          <source src="images/math_teaser_1.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/math_teaser_1.png' width="160">
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:top">
        <a href="https://arxiv.org/pdf/2406.15444">
			<span class="papertitle">Cutting Through the Noise: Boosting LLM Performance on Math Word Problems
</span>
        </a>
        <br>
				<a href="https://him1411.github.io/">Himanshu Gupta</a>,
				<a href="https://ujjwalaananth.github.io/">Ujjwala Anantheswaran</a>,
				<a href="https://kevinscaria.github.io/">Kevin Scaria</a>,
        <strong>Shreyas Verma</strong>,
        <a href="https://sites.google.com/view/mihir3009">Mihir Parmar</a>,
        <a href="https://swarooprm.github.io/">Swaroop Mishra</a>,
        <a href="https://search.asu.edu/profile/231973">Chitta Baral</a>  
        <br>
        <font color=#FF8080><em>ICLR (Workshop)</em>, 2025</font> &nbsp;
        <br>
        <a href="https://arxiv.org/pdf/2406.15444">arXiv</a> 
        <!-- <a href="https://polymathbenchmark.github.io/">website</a> -->
        <!-- <a href="https://github.com/polymathbenchmark/PolyMATH">code</a> / -->
        <!-- <a href="https://huggingface.co/datasets/him1411/polymath">dataset</a> -->
        <p>
          Large Language Models (LLMs) excel at various tasks, including solving math word problems (MWPs), but struggle with real-world problems containing irrelevant information. To address this, we propose a prompting framework that generates adversarial variants of MWPs by adding irrelevant variables. We introduce a dataset, PROBLEMATHIC, containing both adversarial and non-adversarial MWPs.
        </p>
      </td>
    </tr>

    <tr >
      <td style="padding:16px;width:20%;vertical-align:middle;margin-top:5px">
        <div class="one">
          <div class="two" id='context_ner.png'><video  width=100% height=100% muted autoplay loop>
          <source src="images/context_ner.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/context_ner.png' width="160" style="margin-top: 36px">
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2109.08079">
			<span class="papertitle">CONTEXT-NER: Contextual Phrase Generation at Scale
</span>
        </a>
        <br>
				<a href="https://him1411.github.io/">Himanshu Gupta</a>,
        <strong>Shreyas Verma</strong>,
        <a href="https://swarooprm.github.io/">Swaroop Mishra</a>
        <br>
        <font color=#FF8080><em>NeurIPS (Workshop)</em>, 2022</font> &nbsp;
        <br>
        <a href="https://arxiv.org/pdf/2109.08079">arXiv</a> 
        <!-- <a href="https://polymathbenchmark.github.io/">website</a> -->
        <!-- <a href="https://github.com/polymathbenchmark/PolyMATH">code</a> / -->
        <!-- <a href="https://huggingface.co/datasets/him1411/polymath">dataset</a> -->
        <p>
          Named Entity Recognition (NER) has seen significant progress in recent years, with
          numerous state-of-the-art (SOTA) models achieving high performance. However,
          very few studies have focused on the generation of entities’ context. In this paper, we introduce CONTEXT-NER, a task that aims to generate the relevant context
          for entities in a sentence, where the context is a phrase describing the entity but
          not necessarily present in the sentence. 
        </p>
      </td>
    </tr>


          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Work Experience</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="data/Shreyas_Verma_Resume_AS.pdf"> Feb'24 - Present : Gen AI Research @ Simplr AI, an Asurion Company</a>
                <br>
                <a href="data/Shreyas_Verma_Resume_AS.pdf"> Summer'23 : Applied Science Intern @ Zillow </a>
                <br>
                <a href="data/Shreyas_Verma_Resume_AS.pdf">Dec'19 - July'22 : AI Researcher @ American Express</a>
                <br>
              </td>
            </tr>


            <!-- <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a>
								<br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a>
								<br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a>
								<br>
								<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a>
								<br>
								<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>  -->

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Projects</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://arxiv.org/pdf/2312.15576">On Hallucinations in LLMs</a>
                <br>
                <a href="https://github.com/shreyas301197/Instruction-Tuned-Clinical-Notes-Scoring">On Instruction Finetuning</a>
                <br>
                <a href="https://arxiv.org/pdf/2312.15576">On Joint Reasoning from Language Models and Knowledge Graphs</a>
                <br>
                <a href="https://github.com/yma17/politics-knowledge-graph">REP-G : Representing Emerging Politics with Graphs</a>
                
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Teaching Assistant,CSE 6040</a>
                <br>
                
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
